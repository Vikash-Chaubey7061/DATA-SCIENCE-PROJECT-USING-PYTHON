{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJgSu+tisKgsmFDN/7I6Bg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vikash-Chaubey7061/DATA-SCIENCE-PROJECT-USING-PYTHON/blob/main/Vaccination_Data_Analysis_and_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Title - Vaccination Data Analysis and Visualization"
      ],
      "metadata": {
        "id": "sKDCR6Dhy7Xw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project by - Vikash Kumar Chaubey\n"
      ],
      "metadata": {
        "id": "hbDTtjz8zFKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skills take away From This Project -  Python script,data cleaning, EDA, SQL, Power BI"
      ],
      "metadata": {
        "id": "tfGwXWKyzNc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Domain-Public Health and Epidemiology"
      ],
      "metadata": {
        "id": "DEiMRgC2zbSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement:Analyze global vaccination data to understand trends in vaccination coverage, disease incidence, and effectiveness. Data will be cleaned, and stored in a SQL database. Power BI will be used to connect to the SQL database and create interactive dashboards that provide insights on vaccination strategies and their impact on disease control.\n",
        "\n",
        "\n",
        "Business Use Cases:\n",
        "●\tPublic Health Strategy:\n",
        "○\tAssess the effectiveness of vaccination programs in different regions and populations.\n",
        "○\tPrioritize areas with low vaccination coverage for targeted interventions.\n",
        "●\tDisease Prevention:\n",
        "○\tIdentify diseases with high incidence rates despite vaccination efforts, suggesting vaccine inefficacies or areas for improvement.\n",
        "○\tSupport policies on booster vaccines or new vaccine introductions.\n",
        "●\tResource Allocation:\n",
        "○\tDetermine regions with low vaccination coverage and plan targeted resource distribution to improve vaccination rates.\n",
        "○\tForecast vaccine demand based on current trends for better supply chain management.\n",
        "●\tGlobal Health Policy:\n",
        "○\tProvide data-driven recommendations for vaccination policy formulation.\n",
        "○\tSupport governments and health organizations with evidence on vaccine effectiveness.\n",
        "\n",
        "Approach:\n",
        "Data Cleaning.\n",
        "●\tHandle Missing Data: Impute missing values or remove incomplete records.\n",
        "●\tNormalize Units: Ensure consistency in units across datasets (e.g., percentage of coverage, number of reported cases).\n",
        "●\tDate Consistency: Format date fields uniformly across tables for easier analysis.\n",
        "SQL Database Setup\n",
        "●\tCreate Tables: Store the extracted and cleaned data into relational SQL tables (e.g., vaccination data, disease incidence data, antigen data).\n",
        "●\tNormalize Data: Structure the data into separate tables (e.g., vaccines, diseases, countries, years) to avoid redundancy and improve querying performance.\n",
        "●\tData Integrity: Implement primary and foreign keys to ensure referential integrity.\n",
        "Power BI Integration.\n",
        "●\tConnect Power BI to SQL Database:\n",
        "○\tUse Power BI’s SQL connector to link to the SQL database and pull in the relevant tables for analysis.\n",
        "○\tSet up scheduled refreshes for updated data.\n",
        "Data Visualization in Power BI\n",
        "●\tCreate Interactive Dashboards:\n",
        "○\tUse Power BI to create dynamic and visually engaging reports with filters and slicers for users to explore the vaccination data.\n",
        "○\tVisualize vaccination rates, disease incidence, and antigen coverage over time and across regions.\n",
        "●\tKey Visualizations:\n",
        "○\tGeographical Heatmaps: Display vaccination coverage and disease incidence by region.\n",
        "○\tTrend Lines/Bar Charts: Show trends in vaccination coverage, disease rates, and effectiveness over multiple years.\n",
        "○\tScatter Plots: Correlate vaccination coverage and disease incidence across different countries or regions.\n",
        "○\tKPI Indicators: Track progress toward vaccination goals and health targets.\n",
        "\n",
        "Exploratory Data Analysis (EDA):\n",
        "●\tAnalyze vaccination coverage, disease incidence trends, and regional disparities using statistical summaries and correlation analysis. Visualize insights with bar charts, heatmaps, and line graphs to identify patterns, highlight low-coverage areas, and assess the impact of vaccination on disease reduction.\n"
      ],
      "metadata": {
        "id": "CSR4lQkNzljP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment Setup & Data Acquisition\n",
        "\n",
        "Install Required Packages"
      ],
      "metadata": {
        "id": "7slKfBhf0BNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pandas numpy sqlalchemy matplotlib seaborn plotly jupyter notebook\n",
        "%pip install powerbi-api-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djMZLPct0No0",
        "outputId": "28ab8bee-e317-453b-f48a-6d32fe4e1ee8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.43)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (6.5.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from jupyter) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter)\n",
            "  Downloading jupyterlab-4.4.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook) (3.1.6)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from notebook) (6.4.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from notebook) (26.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook) (25.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.12/dist-packages (from notebook) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.12/dist-packages (from notebook) (5.8.1)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.12/dist-packages (from notebook) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.12/dist-packages (from notebook) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook) (5.10.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.12/dist-packages (from notebook) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook) (1.3.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.6.1->notebook) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (2.19.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook) (4.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->notebook) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook) (25.1.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (7.34.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (0.1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (5.9.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (3.0.15)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter) (3.0.51)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter) (0.28.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
            "  Downloading jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter) (75.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook) (0.27.0)\n",
            "Collecting jupyter-client<8,>=5.3.4 (from notebook)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client<8,>=5.3.4->notebook) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.2.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook) (2.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.5)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
            "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
            "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jupyterlab-4.4.6-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, lark, json5, jedi, fqdn, async-lru, rfc3987-syntax, jupyter-server-terminals, jupyter-client, arrow, isoduration, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires jupyter-server==1.16.0, but you have jupyter-server 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 async-lru-2.0.5 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.12.1 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.6 jupyterlab-server-2.27.3 lark-1.2.2 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 types-python-dateutil-2.9.0.20250822 uri-template-1.3.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement powerbi-api-client (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for powerbi-api-client\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Download and Organize Data\n",
        "\n",
        "\n",
        "Create a Python script to download and organize the data:"
      ],
      "metadata": {
        "id": "J9P_bw4H0jgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scripts/data_download.py\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Create directory structure\n",
        "os.makedirs('data/raw', exist_ok=True)\n",
        "os.makedirs('data/processed', exist_ok=True)\n",
        "\n",
        "# Download data (pseudo-code - actual implementation depends on source)\n",
        "def download_data():\n",
        "    # This is a placeholder - you would need to implement actual download logic\n",
        "    # based on how the data is provided at the Google Drive link\n",
        "    data_url = \"https://drive.google.com/drive/folders/1YQ6mNrZCrlEeBP4GH3VnLBNXb7OBD4tf\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(data_url)\n",
        "        with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
        "            z.extractall('data/raw')\n",
        "        print(\"Data downloaded and extracted successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading data: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    download_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYO_tavE0pIv",
        "outputId": "379bad94-83bc-4b5a-f1a8-b49881698fed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading data: File is not a zip file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning & Preprocessing\n",
        "1. Data Cleaning Script"
      ],
      "metadata": {
        "id": "SRUBoKEm1yHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load data automatically from Excel or CSV\"\"\"\n",
        "    if file_path.endswith(\".xlsx\") or file_path.endswith(\".xls\"):\n",
        "        df = pd.read_excel(file_path, engine=\"openpyxl\")\n",
        "    elif file_path.endswith(\".csv\"):\n",
        "        df = pd.read_csv(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format: must be .csv or .xlsx\")\n",
        "    return df\n",
        "\n",
        "def normalize_columns(df):\n",
        "    \"\"\"Normalize column names to lowercase_snake_case\"\"\"\n",
        "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "    return df\n",
        "\n",
        "def clean_coverage_data(file_path):\n",
        "    df = load_data(\"/content/coverage-data.xlsx\")\n",
        "    df = normalize_columns(df)\n",
        "    print(\"Coverage columns:\", df.columns.tolist())  # Debugging\n",
        "    print(df.head(4))\n",
        "    # Handle missing values safely\n",
        "    if \"target_number\" in df.columns:\n",
        "        df[\"target_number\"] = df[\"target_number\"].fillna(0)\n",
        "    if \"doses\" in df.columns:\n",
        "        df[\"doses\"] = df[\"doses\"].fillna(0)\n",
        "    if \"coverage\" in df.columns and \"target_number\" in df.columns and \"doses\" in df.columns:\n",
        "        mask = df[\"coverage\"].isna() & (df[\"target_number\"] > 0)\n",
        "        df.loc[mask, \"coverage\"] = (df.loc[mask, \"doses\"] / df.loc[mask, \"target_number\"]) * 100\n",
        "        df = df.dropna(subset=[\"coverage\"])\n",
        "    if \"code\" in df.columns:\n",
        "        df[\"code\"] = df[\"code\"].str.upper()\n",
        "    return df\n",
        "\n",
        "def clean_incidence_data(file_path):\n",
        "    df = load_data(\"/content/incidence-rate-data.xlsx\")\n",
        "    df = normalize_columns(df)\n",
        "    if \"incidence_rate\" in df.columns:\n",
        "        df[\"incidence_rate\"] = df[\"incidence_rate\"].fillna(0)\n",
        "    if \"code\" in df.columns:\n",
        "        df[\"code\"] = df[\"code\"].str.upper()\n",
        "        print(df.head(4))\n",
        "    return df\n",
        "\n",
        "def clean_reported_cases(file_path):\n",
        "    df = load_data(\"/content/reported-cases-data.xlsx\")\n",
        "    df = normalize_columns(df)\n",
        "    if \"cases\" in df.columns:\n",
        "        df[\"cases\"] = df[\"cases\"].fillna(0)\n",
        "    if \"code\" in df.columns:\n",
        "        df[\"code\"] = df[\"code\"].str.upper()\n",
        "        print(df.head(4))\n",
        "    return df\n",
        "\n",
        "def clean_vaccine_introduction(file_path):\n",
        "    df = load_data(\"/content/vaccine-introduction-data.xlsx\")\n",
        "    df = normalize_columns(df)\n",
        "    if \"intro\" in df.columns:\n",
        "        df[\"intro\"] = df[\"intro\"].fillna(\"No\")\n",
        "    if \"iso_3_code\" in df.columns:\n",
        "        df[\"iso_3_code\"] = df[\"iso_3_code\"].str.upper()\n",
        "        print(df.head(4))\n",
        "    return df\n",
        "\n",
        "def clean_all_data():\n",
        "    \"\"\"Clean all data files\"\"\"\n",
        "    data_dir = \"data/raw\"\n",
        "    processed_dir = \"data/processed\"\n",
        "    os.makedirs(processed_dir, exist_ok=True)\n",
        "\n",
        "    coverage_df = clean_coverage_data(f\"{data_dir}/coverage_data.xlsx\")\n",
        "    incidence_df = clean_incidence_data(f\"{data_dir}/incidence_rate.xlsx\")\n",
        "    cases_df = clean_reported_cases(f\"{data_dir}/reported_cases.xlsx\")\n",
        "    vaccine_intro_df = clean_vaccine_introduction(f\"{data_dir}/vaccine_introduction.xlsx\")\n",
        "\n",
        "    coverage_df.to_csv(f\"{processed_dir}/cleaned_coverage_data.csv\", index=False)\n",
        "    incidence_df.to_csv(f\"{processed_dir}/cleaned_incidence_rate.csv\", index=False)\n",
        "    cases_df.to_csv(f\"{processed_dir}/cleaned_reported_cases.csv\", index=False)\n",
        "    vaccine_intro_df.to_csv(f\"{processed_dir}/cleaned_vaccine_introduction.csv\", index=False)\n",
        "\n",
        "    print(\"All data cleaned and saved successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    clean_all_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzrgCh5Ft5d3",
        "outputId": "310d7367-5338-46bf-dcfb-b229360b967b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage columns: ['group', 'code', 'name', 'year', 'antigen', 'antigen_description', 'coverage_category', 'coverage_category_description', 'target_number', 'doses', 'coverage']\n",
            "       group code   name    year  antigen  \\\n",
            "0  COUNTRIES  ABW  Aruba  2023.0      BCG   \n",
            "1  COUNTRIES  ABW  Aruba  2023.0      BCG   \n",
            "2  COUNTRIES  ABW  Aruba  2023.0  DIPHCV4   \n",
            "3  COUNTRIES  ABW  Aruba  2023.0  DIPHCV4   \n",
            "\n",
            "                                 antigen_description coverage_category  \\\n",
            "0                                                BCG             ADMIN   \n",
            "1                                                BCG          OFFICIAL   \n",
            "2  Diphtheria-containing vaccine, 4th dose (1st b...             ADMIN   \n",
            "3  Diphtheria-containing vaccine, 4th dose (1st b...          OFFICIAL   \n",
            "\n",
            "  coverage_category_description  target_number  doses  coverage  \n",
            "0       Administrative coverage            NaN    NaN       NaN  \n",
            "1             Official coverage            NaN    NaN       NaN  \n",
            "2       Administrative coverage         1044.0  945.0     90.52  \n",
            "3             Official coverage            NaN    NaN     90.52  \n",
            "       group code   name    year          disease  \\\n",
            "0  COUNTRIES  ABW  Aruba  2023.0              CRS   \n",
            "1  COUNTRIES  ABW  Aruba  2023.0       DIPHTHERIA   \n",
            "2  COUNTRIES  ABW  Aruba  2023.0  INVASIVE_MENING   \n",
            "3  COUNTRIES  ABW  Aruba  2023.0          MEASLES   \n",
            "\n",
            "              disease_description                     denominator  \\\n",
            "0     Congenital rubella syndrome          per 10,000 live births   \n",
            "1                      Diphtheria  per 1,000,000 total population   \n",
            "2  Invasive meningococcal disease  per 1,000,000 total population   \n",
            "3                         Measles  per 1,000,000 total population   \n",
            "\n",
            "   incidence_rate  \n",
            "0             0.0  \n",
            "1             0.0  \n",
            "2             9.3  \n",
            "3             0.0  \n",
            "       group code   name    year          disease  \\\n",
            "0  COUNTRIES  ABW  Aruba  2023.0              CRS   \n",
            "1  COUNTRIES  ABW  Aruba  2023.0       DIPHTHERIA   \n",
            "2  COUNTRIES  ABW  Aruba  2023.0  INVASIVE_MENING   \n",
            "3  COUNTRIES  ABW  Aruba  2023.0          MEASLES   \n",
            "\n",
            "              disease_description  cases  \n",
            "0     Congenital rubella syndrome    0.0  \n",
            "1                      Diphtheria    0.0  \n",
            "2  Invasive meningococcal disease    1.0  \n",
            "3                         Measles    0.0  \n",
            "  iso_3_code  countryname who_region    year  \\\n",
            "0        AFG  Afghanistan       EMRO  2023.0   \n",
            "1        AFG  Afghanistan       EMRO  2023.0   \n",
            "2        AFG  Afghanistan       EMRO  2023.0   \n",
            "3        AFG  Afghanistan       EMRO  2023.0   \n",
            "\n",
            "                        description intro  \n",
            "0  aP (acellular pertussis) vaccine    No  \n",
            "1               Hepatitis A vaccine    No  \n",
            "2               Hepatitis B vaccine   Yes  \n",
            "3                   HepB birth dose   Yes  \n",
            "All data cleaned and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL Database Design & Population\n",
        "\n",
        "Database Schema Setup"
      ],
      "metadata": {
        "id": "12arDlhDIKFi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70fbfaa7",
        "outputId": "8665490b-0c84-4b06-f208-bc66e14c84d9"
      },
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# Replace with your actual database connection details\n",
        "# For example, if using SQLite:\n",
        "# DATABASE_URL = \"sqlite:///vaccination_analysis.db\"\n",
        "# If using PostgreSQL:\n",
        "# DATABASE_URL = \"postgresql://user:password@host:port/database\"\n",
        "# If using MySQL:\n",
        "# DATABASE_URL = \"mysql+mysqlconnector://user:password@host:port/database\"\n",
        "\n",
        "# For demonstration purposes, we will use an in-memory SQLite database\n",
        "DATABASE_URL = \"sqlite:///:memory:\"\n",
        "\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# SQL commands to create tables - split into individual statements\n",
        "sql_commands = [\n",
        "    \"\"\"\n",
        "CREATE TABLE dim_country (\n",
        "    country_code VARCHAR(3) PRIMARY KEY,\n",
        "    country_name VARCHAR(100) NOT NULL,\n",
        "    who_region VARCHAR(50)\n",
        ");\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "CREATE TABLE dim_antigen (\n",
        "    antigen_code VARCHAR(10) PRIMARY KEY,\n",
        "    antigen_description TEXT\n",
        ");\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "CREATE TABLE dim_disease (\n",
        "    disease_code VARCHAR(10) PRIMARY KEY,\n",
        "    disease_description TEXT\n",
        ");\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "CREATE TABLE dim_vaccine (\n",
        "    vaccine_code VARCHAR(10) PRIMARY KEY,\n",
        "    vaccine_description TEXT\n",
        ");\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "CREATE TABLE fact_coverage (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    country_code VARCHAR(3) REFERENCES dim_country(country_code),\n",
        "    year INT,\n",
        "    antigen_code VARCHAR(10) REFERENCES dim_antigen(antigen_code),\n",
        "    target_population BIGINT,\n",
        "    doses_administered BIGINT,\n",
        "    coverage_percentage DECIMAL(5,2)\n",
        ");\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "CREATE TABLE fact_incidence (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    country_code VARCHAR(3) REFERENCES dim_country(country_code),\n",
        "    year INT,\n",
        "    disease_code VARCHAR(10) REFERENCES dim_disease(disease_code),\n",
        "    denominator VARCHAR(50),\n",
        "    incidence_rate DECIMAL(10,2)\n",
        ");\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "CREATE TABLE fact_reported_cases (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    country_code VARCHAR(3) REFERENCES dim_country(country_code),\n",
        "    year INT,\n",
        "    disease_code VARCHAR(10) REFERENCES dim_disease(disease_code),\n",
        "    cases_reported INT\n",
        ");\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "CREATE TABLE fact_vaccine_intro (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    country_code VARCHAR(3) REFERENCES dim_country(country_code),\n",
        "    year INT,\n",
        "    vaccine_code VARCHAR(10) REFERENCES dim_vaccine(vaccine_code),\n",
        "    introduced BOOLEAN\n",
        ");\n",
        "\"\"\"\n",
        "]\n",
        "\n",
        "# Execute the SQL commands one by one\n",
        "with engine.connect() as connection:\n",
        "    for command in sql_commands:\n",
        "        connection.execute(text(command))\n",
        "\n",
        "print(\"Database tables created successfully.\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database tables created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Power BI Integration"
      ],
      "metadata": {
        "id": "0dvnQEAJz24K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scripts/powerbi_preparation.py\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "def prepare_powerbi_data():\n",
        "    engine = create_engine('sqlite:///vaccination_analysis.db')\n",
        "\n",
        "    # Create a comprehensive dataset for Power BI\n",
        "    query = \"\"\"\n",
        "    SELECT\n",
        "        c.country_code,\n",
        "        c.country_name,\n",
        "        c.who_region,\n",
        "        fc.year,\n",
        "        fc.antigen_code,\n",
        "        a.antigen_description,\n",
        "        fc.target_population,\n",
        "        fc.doses_administered,\n",
        "        fc.coverage_percentage,\n",
        "        fi.disease_code,\n",
        "        d.disease_description,\n",
        "        fi.denominator,\n",
        "        fi.incidence_rate,\n",
        "        rc.cases_reported,\n",
        "        vi.vaccine_code,\n",
        "        v.vaccine_description,\n",
        "        vi.introduced as vaccine_introduced\n",
        "    FROM dim_country c\n",
        "    LEFT JOIN fact_coverage fc ON c.country_code = fc.country_code\n",
        "    LEFT JOIN dim_antigen a ON fc.antigen_code = a.antigen_code\n",
        "    LEFT JOIN fact_incidence fi ON c.country_code = fi.country_code AND fc.year = fi.year\n",
        "    LEFT JOIN dim_disease d ON fi.disease_code = d.disease_code\n",
        "    LEFT JOIN fact_reported_cases rc ON c.country_code = rc.country_code AND fc.year = rc.year AND fi.disease_code = rc.disease_code\n",
        "    LEFT JOIN fact_vaccine_intro vi ON c.country_code = vi.country_code AND fc.year = vi.year\n",
        "    LEFT JOIN dim_vaccine v ON vi.vaccine_code = v.vaccine_code\n",
        "    \"\"\"\n",
        "\n",
        "    powerbi_data = pd.read_sql(query, engine)\n",
        "    powerbi_data.to_csv('powerbi/vaccination_analysis_dataset.csv', index=False)\n",
        "\n",
        "    print(\"Power BI data preparation completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    prepare_powerbi_data()"
      ],
      "metadata": {
        "id": "BZ0fFx9h0Db2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python Script to Populate Database"
      ],
      "metadata": {
        "id": "f3pvPqdqI_DS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scripts/populate_database.py\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "def populate_database():\n",
        "    # Create database connection\n",
        "    # Ensure this matches the database URL used in the schema setup cell (70fbfaa7)\n",
        "    engine = create_engine('sqlite:///vaccination_analysis.db')  # Using SQLite for simplicity\n",
        "\n",
        "    # Load cleaned data (assuming cleaning script saved as CSVs in data/processed)\n",
        "    try:\n",
        "        coverage_df = pd.read_csv('data/processed/cleaned_coverage_data.csv')\n",
        "        incidence_df = pd.read_csv('data/processed/cleaned_incidence_rate.csv')\n",
        "        cases_df = pd.read_csv('data/processed/cleaned_reported_cases.csv')\n",
        "        # Corrected filename based on cleaning script output\n",
        "        vaccine_intro_df = pd.read_csv('data/processed/cleaned_vaccine_introduction.csv')\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error loading cleaned data: {e}. Please ensure the data cleaning script (cell xI1NWEg31z5W) was run successfully.\")\n",
        "        return\n",
        "\n",
        "    # Create dimension tables\n",
        "    with engine.connect() as conn:\n",
        "        # Create dim_country\n",
        "        # Use the 'code' and 'name' columns from the cleaned dataframes\n",
        "        countries = pd.concat([\n",
        "            coverage_df[['code', 'name']].rename(columns={'code': 'country_code', 'name': 'country_name'}),\n",
        "            incidence_df[['code', 'name']].rename(columns={'code': 'country_code', 'name': 'country_name'}),\n",
        "            cases_df[['code', 'name']].rename(columns={'code': 'country_code', 'name': 'country_name'})\n",
        "        ]).drop_duplicates()\n",
        "\n",
        "        # Add WHO region from vaccine introduction data\n",
        "        # Assuming 'iso_3_code' and 'who_region' are correct in the cleaned vaccine introduction data\n",
        "        who_regions = vaccine_intro_df[['iso_3_code', 'who_region']].drop_duplicates()\n",
        "        countries = countries.merge(who_regions, left_on='country_code', right_on='iso_3_code', how='left')\n",
        "        countries = countries[['country_code', 'country_name', 'who_region']].drop_duplicates()\n",
        "        countries.to_sql('dim_country', conn, if_exists='replace', index=False)\n",
        "\n",
        "        # Create dim_antigen\n",
        "        # Assuming 'antigen' and 'antigen_description' are correct in the cleaned coverage data\n",
        "        antigens = coverage_df[['antigen', 'antigen_description']].drop_duplicates()\n",
        "        antigens.columns = ['antigen_code', 'antigen_description']\n",
        "        antigens.to_sql('dim_antigen', conn, if_exists='replace', index=False)\n",
        "\n",
        "        # Create dim_disease\n",
        "        # Assuming 'disease' and 'disease_description' are correct in the cleaned incidence and cases data\n",
        "        diseases = pd.concat([\n",
        "            incidence_df[['disease', 'disease_description']].rename(columns={'disease': 'disease_code', 'disease_description': 'disease_description'}),\n",
        "            cases_df[['disease', 'disease_description']].rename(columns={'disease': 'disease_code', 'disease_description': 'disease_description'})\n",
        "        ]).drop_duplicates()\n",
        "        diseases.to_sql('dim_disease', conn, if_exists='replace', index=False)\n",
        "\n",
        "        # Create dim_vaccine\n",
        "        # Assuming 'description' is correct in the cleaned vaccine introduction data\n",
        "        vaccines = vaccine_intro_df[['description']].drop_duplicates()\n",
        "        vaccines['vaccine_code'] = vaccines['description'].str[:10]  # Simplified code generation\n",
        "        vaccines = vaccines[['vaccine_code', 'description']].rename(columns={'description': 'vaccine_description'})\n",
        "        vaccines.to_sql('dim_vaccine', conn, if_exists='replace', index=False)\n",
        "\n",
        "        # Populate fact tables\n",
        "        # Fact coverage\n",
        "        # Assuming correct column names in cleaned coverage data (now lowercase)\n",
        "        fact_coverage = coverage_df[['code', 'year', 'antigen', 'target_number', 'doses', 'coverage']]\n",
        "        fact_coverage.columns = ['country_code', 'year', 'antigen_code', 'target_population', 'doses_administered', 'coverage_percentage']\n",
        "        fact_coverage.to_sql('fact_coverage', conn, if_exists='append', index=False)\n",
        "\n",
        "        # Fact incidence\n",
        "        # Assuming correct column names in cleaned incidence data (now lowercase)\n",
        "        fact_incidence = incidence_df[['code', 'year', 'disease', 'denominator', 'incidence_rate']]\n",
        "        fact_incidence.columns = ['country_code', 'year', 'disease_code', 'denominator', 'incidence_rate']\n",
        "        fact_incidence.to_sql('fact_incidence', conn, if_exists='append', index=False)\n",
        "\n",
        "        # Fact reported cases\n",
        "        # Assuming correct column names in cleaned reported cases data (now lowercase)\n",
        "        fact_cases = cases_df[['code', 'year', 'disease', 'cases']]\n",
        "        fact_cases.columns = ['country_code', 'year', 'disease_code', 'cases_reported']\n",
        "        fact_cases.to_sql('fact_reported_cases', conn, if_exists='append', index=False)\n",
        "\n",
        "        # Fact vaccine introduction\n",
        "        # Assuming correct column names in cleaned vaccine introduction data (now lowercase)\n",
        "        fact_vaccine_intro = vaccine_intro_df[['iso_3_code', 'year', 'description', 'intro']]\n",
        "        fact_vaccine_intro['vaccine_code'] = fact_vaccine_intro['description'].str[:10]\n",
        "        fact_vaccine_intro['introduced'] = fact_vaccine_intro['intro'].apply(lambda x: True if x == 'Yes' else False)\n",
        "        fact_vaccine_intro = fact_vaccine_intro[['iso_3_code', 'year', 'vaccine_code', 'introduced']]\n",
        "        fact_vaccine_intro.columns = ['country_code', 'year', 'vaccine_code', 'introduced']\n",
        "        fact_vaccine_intro.to_sql('fact_vaccine_intro', conn, if_exists='append', index=False)\n",
        "\n",
        "\n",
        "    print(\"Database populated successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    populate_database()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pveu4u7JCD8",
        "outputId": "8ba4a68f-fd7d-4250-9945-bcc323eb3c83"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1789041835.py:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  fact_vaccine_intro['vaccine_code'] = fact_vaccine_intro['description'].str[:10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database populated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "PvXmGv9NJHCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scripts/exploratory_analysis.py\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine\n",
        "import os\n",
        "\n",
        "# Set up visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "def perform_eda():\n",
        "    # Connect to database\n",
        "    engine = create_engine('sqlite:///vaccination_analysis.db')\n",
        "\n",
        "    # Create visualizations directory if it doesn't exist\n",
        "    os.makedirs('visualizations', exist_ok=True)\n",
        "\n",
        "    # Query 1: Global vaccination coverage over time\n",
        "    query1 = \"\"\"\n",
        "    SELECT year, AVG(coverage_percentage) as avg_coverage\n",
        "    FROM fact_coverage\n",
        "    GROUP BY year\n",
        "    ORDER BY year\n",
        "    \"\"\"\n",
        "    coverage_trend = pd.read_sql(query1, engine)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(coverage_trend['year'], coverage_trend['avg_coverage'])\n",
        "    plt.title('Global Vaccination Coverage Over Time')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Average Coverage (%)')\n",
        "    plt.savefig('visualizations/global_coverage_trend.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Query 2: Correlation between vaccination coverage and disease incidence\n",
        "    query2 = \"\"\"\n",
        "    SELECT c.country_code, c.year, c.antigen_code, c.coverage_percentage,\n",
        "           i.disease_code, i.incidence_rate\n",
        "    FROM fact_coverage c\n",
        "    JOIN fact_incidence i ON c.country_code = i.country_code AND c.year = i.year\n",
        "    WHERE c.antigen_code = 'Measles' AND i.disease_code = 'Measles'\n",
        "    \"\"\"\n",
        "    correlation_data = pd.read_sql(query2, engine)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.scatter(correlation_data['coverage_percentage'], correlation_data['incidence_rate'], alpha=0.5)\n",
        "    plt.title('Correlation: Measles Vaccination Coverage vs Incidence Rate')\n",
        "    plt.xlabel('Vaccination Coverage (%)')\n",
        "    plt.ylabel('Incidence Rate')\n",
        "    plt.savefig('visualizations/coverage_vs_incidence.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Query 3: Top 10 countries with lowest vaccination coverage\n",
        "    query3 = \"\"\"\n",
        "    SELECT c.country_name, AVG(f.coverage_percentage) as avg_coverage\n",
        "    FROM fact_coverage f\n",
        "    JOIN dim_country c ON f.country_code = c.country_code\n",
        "    GROUP BY c.country_name\n",
        "    ORDER BY avg_coverage ASC\n",
        "    LIMIT 10\n",
        "    \"\"\"\n",
        "    low_coverage = pd.read_sql(query3, engine)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.barh(low_coverage['country_name'], low_coverage['avg_coverage'])\n",
        "    plt.title('Top 10 Countries with Lowest Vaccination Coverage')\n",
        "    plt.xlabel('Average Coverage (%)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('visualizations/low_coverage_countries.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Query 4: Disease incidence by WHO region\n",
        "    query4 = \"\"\"\n",
        "    SELECT c.who_region, AVG(i.incidence_rate) as avg_incidence\n",
        "    FROM fact_incidence i\n",
        "    JOIN dim_country c ON i.country_code = c.country_code\n",
        "    GROUP BY c.who_region\n",
        "    ORDER BY avg_incidence DESC\n",
        "    \"\"\"\n",
        "    region_incidence = pd.read_sql(query4, engine)\n",
        "\n",
        "    # Drop rows with None in 'who_region' before plotting\n",
        "    region_incidence = region_incidence.dropna(subset=['who_region'])\n",
        "\n",
        "    plt.figure()\n",
        "    plt.bar(region_incidence['who_region'], region_incidence['avg_incidence'])\n",
        "    plt.title('Average Disease Incidence by WHO Region')\n",
        "    plt.xlabel('WHO Region')\n",
        "    plt.ylabel('Average Incidence Rate')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('visualizations/incidence_by_region.png')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"EDA completed. Visualizations saved.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    perform_eda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rFDwtfGJIl2",
        "outputId": "bf19fcd5-3ac4-4a70-dc22-62166318ef91"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EDA completed. Visualizations saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL Queries for Answering Questions"
      ],
      "metadata": {
        "id": "d-rvBwUxJPxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scripts/sql_queries.py\n",
        "from sqlalchemy import create_engine, text\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def run_analysis_queries():\n",
        "    engine = create_engine('sqlite:///vaccination_analysis.db')\n",
        "\n",
        "    # Create results directory if it doesn't exist\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "\n",
        "    # Query to answer: How do vaccination rates correlate with a decrease in disease incidence?\n",
        "    query1 = \"\"\"\n",
        "    SELECT\n",
        "        c.country_name,\n",
        "        c.who_region,\n",
        "        fc.antigen_code,\n",
        "        fc.year,\n",
        "        fc.coverage_percentage,\n",
        "        fi.incidence_rate,\n",
        "        (LAG(fi.incidence_rate) OVER (PARTITION BY c.country_code, fc.antigen_code ORDER BY fc.year) - fi.incidence_rate)\n",
        "            as incidence_change\n",
        "    FROM fact_coverage fc\n",
        "    JOIN fact_incidence fi ON fc.country_code = fi.country_code AND fc.year = fi.year\n",
        "    JOIN dim_country c ON fc.country_code = c.country_code\n",
        "    WHERE fc.antigen_code = 'Measles' AND fi.disease_code = 'Measles'\n",
        "    ORDER BY c.country_name, fc.year\n",
        "    \"\"\"\n",
        "\n",
        "    # Query to answer: What is the drop-off rate between 1st dose and subsequent doses?\n",
        "    query2 = \"\"\"\n",
        "    WITH dose_coverage AS (\n",
        "        SELECT\n",
        "            country_code,\n",
        "            year,\n",
        "            CASE\n",
        "                WHEN antigen_code LIKE '%1%' THEN 'First Dose'\n",
        "                WHEN antigen_code LIKE '%2%' THEN 'Second Dose'\n",
        "                WHEN antigen_code LIKE '%3%' THEN 'Third Dose'\n",
        "                ELSE 'Other'\n",
        "            END as dose_type,\n",
        "            AVG(coverage_percentage) as avg_coverage\n",
        "        FROM fact_coverage\n",
        "        GROUP BY country_code, year, dose_type\n",
        "    )\n",
        "    SELECT\n",
        "        dc1.country_code,\n",
        "        dc1.year,\n",
        "        dc1.avg_coverage as first_dose_coverage,\n",
        "        dc2.avg_coverage as second_dose_coverage,\n",
        "        (dc1.avg_coverage - dc2.avg_coverage) as drop_off\n",
        "    FROM dose_coverage dc1\n",
        "    JOIN dose_coverage dc2 ON dc1.country_code = dc2.country_code AND dc1.year = dc2.year\n",
        "    WHERE dc1.dose_type = 'First Dose' AND dc2.dose_type = 'Second Dose'\n",
        "    \"\"\"\n",
        "\n",
        "    # Query to answer: Which regions have high disease incidence despite high vaccination rates?\n",
        "    query3 = \"\"\"\n",
        "    WITH region_stats AS (\n",
        "        SELECT\n",
        "            c.who_region,\n",
        "            AVG(fc.coverage_percentage) as avg_coverage,\n",
        "            AVG(fi.incidence_rate) as avg_incidence\n",
        "        FROM fact_coverage fc\n",
        "        JOIN fact_incidence fi ON fc.country_code = fi.country_code AND fc.year = fi.year\n",
        "        JOIN dim_country c ON fc.country_code = c.country_code\n",
        "        WHERE fc.antigen_code = 'Measles' AND fi.disease_code = 'Measles'\n",
        "        GROUP BY c.who_region\n",
        "    )\n",
        "    SELECT\n",
        "        who_region,\n",
        "        avg_coverage,\n",
        "        avg_incidence,\n",
        "        CASE\n",
        "            WHEN avg_coverage > 80 AND avg_incidence > 50 THEN 'High Coverage, High Incidence'\n",
        "            ELSE 'Other'\n",
        "        END as status\n",
        "    FROM region_stats\n",
        "    ORDER BY avg_incidence DESC\n",
        "    \"\"\"\n",
        "\n",
        "    # Execute queries and save results\n",
        "    with engine.connect() as conn:\n",
        "        result1 = pd.read_sql(text(query1), conn)\n",
        "        result2 = pd.read_sql(text(query2), conn)\n",
        "        result3 = pd.read_sql(text(query3), conn)\n",
        "\n",
        "        result1.to_csv('results/vaccination_incidence_correlation.csv', index=False)\n",
        "        result2.to_csv('results/dose_drop_off.csv', index=False)\n",
        "        result3.to_csv('results/high_incidence_high_coverage.csv', index=False)\n",
        "\n",
        "    print(\"Analysis queries executed and results saved.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_analysis_queries()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAg_lnaHJRSL",
        "outputId": "06142d37-7ffa-442d-e58d-a9f67f01e02c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis queries executed and results saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Power BI Integration"
      ],
      "metadata": {
        "id": "N_tdSBmGJXtg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c33907e1",
        "outputId": "a8fdf997-0b6e-4bae-b2ef-8f7cacb717e8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    df_incidence_cleaned_test = pd.read_csv('data/processed/cleaned_incidence_rate.csv')\n",
        "    print(df_incidence_cleaned_test.columns)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: cleaned_incidence_rate.csv not found. Please ensure the data cleaning step was successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the CSV file: {e}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: cleaned_incidence_rate.csv not found. Please ensure the data cleaning step was successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd98d537",
        "outputId": "4c2ead5a-28b4-4acb-cb51-6617c653c5be"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    df_cases_test = pd.read_excel('/content/reported-cases-data.xlsx')\n",
        "    print(df_cases_test.columns)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: reported-cases-data.xlsx not found. Please ensure the file is in the /content directory.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the Excel file: {e}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['GROUP', 'CODE', 'NAME', 'YEAR', 'DISEASE', 'DISEASE_DESCRIPTION',\n",
            "       'CASES'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Power BI Connection Script (Python)"
      ],
      "metadata": {
        "id": "Er_YmfNm2XB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# powerbi_connection_setup.py\n",
        "import pandas as pd\n",
        "import pyodbc\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "def create_powerbi_connection():\n",
        "    \"\"\"\n",
        "    Create a connection to SQL database for Power BI\n",
        "    \"\"\"\n",
        "    # Database connection parameters\n",
        "    server = 'your_server_name'\n",
        "    database = 'vaccination_analysis'\n",
        "    username = 'Vikash1'\n",
        "    password = 'Vikash@123'\n",
        "\n",
        "    # Create connection string\n",
        "    connection_string = f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
        "\n",
        "    # Create SQLAlchemy engine\n",
        "    engine = create_engine(connection_string)\n",
        "\n",
        "    # Test connection\n",
        "    try:\n",
        "        with engine.connect() as conn:\n",
        "            print(\"Successfully connected to the database!\")\n",
        "            return engine\n",
        "    except Exception as e:\n",
        "        print(f\"Connection failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def export_data_for_powerbi(engine):\n",
        "    \"\"\"\n",
        "    Export data views specifically for Power BI\n",
        "    \"\"\"\n",
        "    # Create a comprehensive view for Power BI\n",
        "    query = \"\"\"\n",
        "    CREATE VIEW powerbi_vaccination_view AS\n",
        "    SELECT\n",
        "        c.country_code,\n",
        "        c.country_name,\n",
        "        c.who_region,\n",
        "        fc.year,\n",
        "        fc.antigen_code,\n",
        "        a.antigen_description,\n",
        "        fc.target_population,\n",
        "        fc.doses_administered,\n",
        "        fc.coverage_percentage,\n",
        "        fi.disease_code,\n",
        "        d.disease_description,\n",
        "        fi.denominator,\n",
        "        fi.incidence_rate,\n",
        "        rc.cases_reported,\n",
        "        vi.vaccine_code,\n",
        "        v.vaccine_description,\n",
        "        vi.introduced as vaccine_introduced\n",
        "    FROM dim_country c\n",
        "    LEFT JOIN fact_coverage fc ON c.country_code = fc.country_code\n",
        "    LEFT JOIN dim_antigen a ON fc.antigen_code = a.antigen_code\n",
        "    LEFT JOIN fact_incidence fi ON c.country_code = fi.country_code AND fc.year = fi.year\n",
        "    LEFT JOIN dim_disease d ON fi.disease_code = d.disease_code\n",
        "    LEFT JOIN fact_reported_cases rc ON c.country_code = rc.country_code AND fc.year = rc.year AND fi.disease_code = rc.disease_code\n",
        "    LEFT JOIN fact_vaccine_intro vi ON c.country_code = vi.country_code AND fc.year = vi.year\n",
        "    LEFT JOIN dim_vaccine v ON vi.vaccine_code = v.vaccine_code\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        with engine.connect() as conn:\n",
        "            conn.execute(\"DROP VIEW IF EXISTS powerbi_vaccination_view\")\n",
        "            conn.execute(query)\n",
        "            print(\"Power BI view created successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating view: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    engine = create_powerbi_connection()\n",
        "    if engine:\n",
        "        export_data_for_powerbi(engine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFk3Eqax2cjp",
        "outputId": "2e8097e1-7d36-43da-f334-a7fd3635b3c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection failed: (pyodbc.Error) ('01000', \"[01000] [unixODBC][Driver Manager]Can't open lib 'ODBC Driver 17 for SQL Server' : file not found (0) (SQLDriverConnect)\")\n",
            "(Background on this error at: https://sqlalche.me/e/20/dbapi)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1274bda5",
        "outputId": "a5ee7536-c5fe-48cc-ecf6-3eb62ac2c9da"
      },
      "source": [
        "%pip install pyodbc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyodbc\n",
            "  Downloading pyodbc-5.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading pyodbc-5.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/354.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/354.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.0/354.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyodbc\n",
            "Successfully installed pyodbc-5.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Power BI Template with DAX Measures"
      ],
      "metadata": {
        "id": "1qTVlPzk2v61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# powerbi_template.py\n",
        "def generate_dax_measures():\n",
        "    \"\"\"\n",
        "    Generate DAX measures for Power BI\n",
        "    \"\"\"\n",
        "    dax_measures = {\n",
        "        \"Avg Coverage\": \"AVERAGE(fact_coverage[coverage_percentage])\",\n",
        "        \"Total Cases\": \"SUM(fact_reported_cases[cases_reported])\",\n",
        "        \"Avg Incidence Rate\": \"AVERAGE(fact_incidence[incidence_rate])\",\n",
        "        \"Total Doses Administered\": \"SUM(fact_coverage[doses_administered])\",\n",
        "        \"Total Target Population\": \"SUM(fact_coverage[target_population])\",\n",
        "        \"Coverage vs Incidence Correlation\":\n",
        "            \"\"\"VAR CoverageValue = [Avg Coverage]\n",
        "            VAR IncidenceValue = [Avg Incidence Rate]\n",
        "            RETURN\n",
        "            IF(NOT ISBLANK(CoverageValue) && NOT ISBLANK(IncidenceValue),\n",
        "               (CoverageValue / 100) * (1 - (IncidenceValue / 1000)),\n",
        "               BLANK()\n",
        "            )\"\"\",\n",
        "        \"YoY Coverage Change\":\n",
        "            \"\"\"VAR CurrentYear = [Avg Coverage]\n",
        "            VAR PreviousYear = CALCULATE([Avg Coverage], SAMEPERIODLASTYEAR(dim_date[date]))\n",
        "            RETURN\n",
        "            IF(NOT ISBLANK(PreviousYear), (CurrentYear - PreviousYear) / PreviousYear, BLANK())\"\"\",\n",
        "        \"Countries with High Coverage\":\n",
        "            \"CALCULATE(DISTINCTCOUNT(dim_country[country_code]), fact_coverage[coverage_percentage] > 90)\",\n",
        "        \"Disease Reduction Percentage\":\n",
        "            \"\"\"VAR MaxCases = MAXX(ALLSELECTED(fact_reported_cases), [Total Cases])\n",
        "            VAR CurrentCases = [Total Cases]\n",
        "            RETURN\n",
        "            IF(MaxCases > 0, (MaxCases - CurrentCases) / MaxCases, BLANK())\"\"\"\n",
        "    }\n",
        "\n",
        "    return dax_measures\n",
        "\n",
        "def create_powerbi_template():\n",
        "    \"\"\"\n",
        "    Create a template Power BI file with predefined measures\n",
        "    \"\"\"\n",
        "    template = {\n",
        "        \"version\": \"1.0\",\n",
        "        \"pages\": [\n",
        "            {\n",
        "                \"name\": \"Global Overview\",\n",
        "                \"visuals\": [\n",
        "                    {\n",
        "                        \"type\": \"map\",\n",
        "                        \"title\": \"Global Vaccination Coverage\",\n",
        "                        \"fields\": {\n",
        "                            \"location\": \"dim_country[country_name]\",\n",
        "                            \"latitude\": \"dim_country[latitude]\",\n",
        "                            \"longitude\": \"dim_country[longitude]\",\n",
        "                            \"color\": \"fact_coverage[coverage_percentage]\",\n",
        "                            \"tooltips\": [\n",
        "                                \"dim_country[country_name]\",\n",
        "                                \"dim_country[who_region]\",\n",
        "                                \"fact_coverage[coverage_percentage]\"\n",
        "                            ]\n",
        "                        }\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"kpi\",\n",
        "                        \"title\": \"Vaccination Coverage KPI\",\n",
        "                        \"fields\": {\n",
        "                            \"value\": \"[Avg Coverage]\",\n",
        "                            \"target\": 90,\n",
        "                            \"trend\": \"[YoY Coverage Change]\"\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return template\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    measures = generate_dax_measures()\n",
        "    template = create_powerbi_template()\n",
        "\n",
        "    print(\"DAX Measures:\")\n",
        "    for measure_name, formula in measures.items():\n",
        "        print(f\"{measure_name}: {formula}\")\n",
        "\n",
        "    print(\"\\nPower BI Template created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj6E9nEg2yGn",
        "outputId": "cabbf83a-3621-4f74-e31a-483ffe46338c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAX Measures:\n",
            "Avg Coverage: AVERAGE(fact_coverage[coverage_percentage])\n",
            "Total Cases: SUM(fact_reported_cases[cases_reported])\n",
            "Avg Incidence Rate: AVERAGE(fact_incidence[incidence_rate])\n",
            "Total Doses Administered: SUM(fact_coverage[doses_administered])\n",
            "Total Target Population: SUM(fact_coverage[target_population])\n",
            "Coverage vs Incidence Correlation: VAR CoverageValue = [Avg Coverage]\n",
            "            VAR IncidenceValue = [Avg Incidence Rate]\n",
            "            RETURN\n",
            "            IF(NOT ISBLANK(CoverageValue) && NOT ISBLANK(IncidenceValue), \n",
            "               (CoverageValue / 100) * (1 - (IncidenceValue / 1000)), \n",
            "               BLANK()\n",
            "            )\n",
            "YoY Coverage Change: VAR CurrentYear = [Avg Coverage]\n",
            "            VAR PreviousYear = CALCULATE([Avg Coverage], SAMEPERIODLASTYEAR(dim_date[date]))\n",
            "            RETURN\n",
            "            IF(NOT ISBLANK(PreviousYear), (CurrentYear - PreviousYear) / PreviousYear, BLANK())\n",
            "Countries with High Coverage: CALCULATE(DISTINCTCOUNT(dim_country[country_code]), fact_coverage[coverage_percentage] > 90)\n",
            "Disease Reduction Percentage: VAR MaxCases = MAXX(ALLSELECTED(fact_reported_cases), [Total Cases])\n",
            "            VAR CurrentCases = [Total Cases]\n",
            "            RETURN\n",
            "            IF(MaxCases > 0, (MaxCases - CurrentCases) / MaxCases, BLANK())\n",
            "\n",
            "Power BI Template created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Complete Power BI Dashboard Implementation"
      ],
      "metadata": {
        "id": "-j-a3lAU3AfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# powerbi_dashboard_creator.py\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from datetime import datetime\n",
        "\n",
        "def create_powerbi_file(template_path, output_path):\n",
        "    \"\"\"\n",
        "    Create a Power BI file with all the visualizations\n",
        "    \"\"\"\n",
        "    # This is a simplified version - in practice, you would use the Power BI REST API\n",
        "    # or the XMLA endpoint to programmatically create Power BI files\n",
        "\n",
        "    print(\"Creating Power BI template with the following structure:\")\n",
        "\n",
        "    # Dashboard structure\n",
        "    dashboard_structure = {\n",
        "        \"Pages\": [\n",
        "            {\n",
        "                \"Name\": \"Global Overview\",\n",
        "                \"Visuals\": [\n",
        "                    \"World Map - Vaccination Coverage\",\n",
        "                    \"KPI Indicators\",\n",
        "                    \"Time Trend - Coverage by Region\",\n",
        "                    \"Top 10 Countries by Coverage\"\n",
        "                ]\n",
        "            },\n",
        "            {\n",
        "                \"Name\": \"Disease Analysis\",\n",
        "                \"Visuals\": [\n",
        "                    \"Disease Incidence by Region\",\n",
        "                    \"Vaccine Impact Scatter Plot\",\n",
        "                    \"Top Diseases Treemap\",\n",
        "                    \"Coverage vs Incidence Correlation\"\n",
        "                ]\n",
        "            },\n",
        "            {\n",
        "                \"Name\": \"Regional Analysis\",\n",
        "                \"Visuals\": [\n",
        "                    \"Regional Comparison Bar Chart\",\n",
        "                    \"Coverage by Antigen\",\n",
        "                    \"Incidence Rate Heatmap\",\n",
        "                    \"Vaccine Introduction Timeline\"\n",
        "                ]\n",
        "            },\n",
        "            {\n",
        "                \"Name\": \"Time Analysis\",\n",
        "                \"Visuals\": [\n",
        "                    \"Coverage Trend Over Time\",\n",
        "                    \"Disease Cases Over Time\",\n",
        "                    \"YoY Change Analysis\",\n",
        "                    \"Seasonal Patterns\"\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Print the structure\n",
        "    for page in dashboard_structure[\"Pages\"]:\n",
        "        print(f\"\\nPage: {page['Name']}\")\n",
        "        for visual in page[\"Visuals\"]:\n",
        "            print(f\"  - {visual}\")\n",
        "\n",
        "    print(f\"\\nPower BI template structure created. Save as {output_path}\")\n",
        "\n",
        "def generate_powerbi_script():\n",
        "    \"\"\"\n",
        "    Generate a Power BI script with all DAX measures and visualizations\n",
        "    \"\"\"\n",
        "    script = \"\"\"\n",
        "// Power BI Script for Vaccination Data Analysis\n",
        "// This script contains all the DAX measures and visualization settings\n",
        "\n",
        "// ===== DATA MODEL =====\n",
        "// Relationships:\n",
        "// fact_coverage[country_code] -> dim_country[country_code]\n",
        "// fact_incidence[country_code] -> dim_country[country_code]\n",
        "// fact_coverage[antigen_code] -> dim_antigen[antigen_code]\n",
        "// fact_incidence[disease_code] -> dim_disease[disease_code]\n",
        "\n",
        "// ===== DAX MEASURES =====\n",
        "Avg Coverage = AVERAGE(fact_coverage[coverage_percentage])\n",
        "\n",
        "Total Cases = SUM(fact_reported_cases[cases_reported])\n",
        "\n",
        "Avg Incidence Rate = AVERAGE(fact_incidence[incidence_rate])\n",
        "\n",
        "Total Doses Administered = SUM(fact_coverage[doses_administered])\n",
        "\n",
        "Total Target Population = SUM(fact_coverage[target_population])\n",
        "\n",
        "Coverage vs Incidence Correlation =\n",
        "VAR CoverageValue = [Avg Coverage]\n",
        "VAR IncidenceValue = [Avg Incidence Rate]\n",
        "RETURN\n",
        "IF(NOT ISBLANK(CoverageValue) && NOT ISBLANK(IncidenceValue),\n",
        "   (CoverageValue / 100) * (1 - (IncidenceValue / 1000)),\n",
        "   BLANK()\n",
        ")\n",
        "\n",
        "YoY Coverage Change =\n",
        "VAR CurrentYear = [Avg Coverage]\n",
        "VAR PreviousYear = CALCULATE([Avg Coverage], SAMEPERIODLASTYEAR(dim_date[date]))\n",
        "RETURN\n",
        "IF(NOT ISBLANK(PreviousYear), (CurrentYear - PreviousYear) / PreviousYear, BLANK())\n",
        "\n",
        "Countries with High Coverage =\n",
        "CALCULATE(DISTINCTCOUNT(dim_country[country_code]), fact_coverage[coverage_percentage] > 90)\n",
        "\n",
        "Disease Reduction Percentage =\n",
        "VAR MaxCases = MAXX(ALLSELECTED(fact_reported_cases), [Total Cases])\n",
        "VAR CurrentCases = [Total Cases]\n",
        "RETURN\n",
        "IF(MaxCases > 0, (MaxCases - CurrentCases) / MaxCases, BLANK())\n",
        "\n",
        "// ===== VISUALIZATION SETTINGS =====\n",
        "// Page 1: Global Overview\n",
        "// - World Map: Location=country_name, Color saturation=coverage_percentage\n",
        "// - KPI Cards: Avg Coverage, Total Cases, Avg Incidence Rate, Countries with High Coverage\n",
        "// - Line Chart: X=Year, Y=Avg Coverage, Legend=who_region\n",
        "// - Bar Chart: Top 10 countries by coverage_percentage\n",
        "\n",
        "// Page 2: Disease Analysis\n",
        "// - Stacked Bar Chart: X=who_region, Y=incidence_rate, Legend=disease_description\n",
        "// - Scatter Plot: X=coverage_percentage, Y=incidence_rate, Size=cases_reported\n",
        "// - Treemap: Values=cases_reported, Details=disease_description\n",
        "// - Correlation Chart: X=coverage_percentage, Y=incidence_rate by disease\n",
        "\n",
        "// Page 3: Regional Analysis\n",
        "// - Bar Chart: Comparison of coverage_percentage by who_region\n",
        "// - Donut Chart: Coverage by antigen_description\n",
        "// - Heatmap: Matrix of who_region vs disease_code with incidence_rate as values\n",
        "// - Timeline: Vaccine introduction dates by country\n",
        "\n",
        "// Page 4: Time Analysis\n",
        "// - Line Chart: coverage_percentage over time by who_region\n",
        "// - Area Chart: cases_reported over time by disease_description\n",
        "// - Waterfall Chart: YoY Change in coverage_percentage\n",
        "// - Seasonal Pattern: Monthly vaccination trends\n",
        "\n",
        "// ===== FILTERS AND SLICERS =====\n",
        "// - Year slicer: Range of years available\n",
        "// - Region slicer: Multi-select who_region\n",
        "// - Disease slicer: Multi-select disease_description\n",
        "// - Vaccine slicer: Multi-select antigen_description\n",
        "// - Country slicer: Multi-select country_name\n",
        "\n",
        "// ===== INTERACTIONS =====\n",
        "// - Cross-filtering enabled between all visuals\n",
        "// - Tooltips showing detailed information on hover\n",
        "// - Drill-through from country level to regional level\n",
        "// - Bookmark navigation between different views\n",
        "\"\"\"\n",
        "\n",
        "    return script\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to create the Power BI dashboard\n",
        "    \"\"\"\n",
        "    print(\"Creating Power BI Dashboard for Vaccination Data Analysis\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create the Power BI file structure\n",
        "    create_powerbi_file(\"template.pbit\", \"vaccination_analysis.pbix\")\n",
        "\n",
        "    # Generate the DAX measures and visualization script\n",
        "    script = generate_powerbi_script()\n",
        "\n",
        "    # Save the script to a file\n",
        "    with open(\"powerbi_implementation_guide.txt\", \"w\") as f:\n",
        "        f.write(script)\n",
        "\n",
        "    print(\"\\nPower BI implementation guide saved to 'powerbi_implementation_guide.txt'\")\n",
        "    print(\"\\nNext steps:\")\n",
        "    print(\"1. Connect Power BI to your SQL database\")\n",
        "    print(\"2. Create the data model with relationships\")\n",
        "    print(\"3. Implement the DAX measures\")\n",
        "    print(\"4. Build the visualizations as described\")\n",
        "    print(\"5. Add filters and slicers for interactivity\")\n",
        "    print(\"6. Test the dashboard and refine as needed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daEOUNyh3B6v",
        "outputId": "807889a1-c384-487d-93fb-4bbf521d78d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Power BI Dashboard for Vaccination Data Analysis\n",
            "============================================================\n",
            "Creating Power BI template with the following structure:\n",
            "\n",
            "Page: Global Overview\n",
            "  - World Map - Vaccination Coverage\n",
            "  - KPI Indicators\n",
            "  - Time Trend - Coverage by Region\n",
            "  - Top 10 Countries by Coverage\n",
            "\n",
            "Page: Disease Analysis\n",
            "  - Disease Incidence by Region\n",
            "  - Vaccine Impact Scatter Plot\n",
            "  - Top Diseases Treemap\n",
            "  - Coverage vs Incidence Correlation\n",
            "\n",
            "Page: Regional Analysis\n",
            "  - Regional Comparison Bar Chart\n",
            "  - Coverage by Antigen\n",
            "  - Incidence Rate Heatmap\n",
            "  - Vaccine Introduction Timeline\n",
            "\n",
            "Page: Time Analysis\n",
            "  - Coverage Trend Over Time\n",
            "  - Disease Cases Over Time\n",
            "  - YoY Change Analysis\n",
            "  - Seasonal Patterns\n",
            "\n",
            "Power BI template structure created. Save as vaccination_analysis.pbix\n",
            "\n",
            "Power BI implementation guide saved to 'powerbi_implementation_guide.txt'\n",
            "\n",
            "Next steps:\n",
            "1. Connect Power BI to your SQL database\n",
            "2. Create the data model with relationships\n",
            "3. Implement the DAX measures\n",
            "4. Build the visualizations as described\n",
            "5. Add filters and slicers for interactivity\n",
            "6. Test the dashboard and refine as needed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Power BI Deployment Script"
      ],
      "metadata": {
        "id": "IyfQiCBp3KYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# powerbi_deployment.py\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "class PowerBIDeployer:\n",
        "    def __init__(self, client_id, client_secret, tenant_id):\n",
        "        self.client_id = client_id\n",
        "        self.client_secret = client_secret\n",
        "        self.tenant_id = tenant_id\n",
        "        self.access_token = None\n",
        "\n",
        "    def authenticate(self):\n",
        "        \"\"\"\n",
        "        Authenticate with Power BI service\n",
        "        \"\"\"\n",
        "        auth_url = f\"https://login.microsoftonline.com/{self.tenant_id}/oauth2/token\"\n",
        "        data = {\n",
        "            'grant_type': 'client_credentials',\n",
        "            'client_id': self.client_id,\n",
        "            'client_secret': self.client_secret,\n",
        "            'resource': 'https://analysis.windows.net/powerbi/api'\n",
        "        }\n",
        "\n",
        "        response = requests.post(auth_url, data=data)\n",
        "        if response.status_code == 200:\n",
        "            self.access_token = response.json()['access_token']\n",
        "            print(\"Authentication successful!\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Authentication failed: {response.text}\")\n",
        "            return False\n",
        "\n",
        "    def deploy_report(self, file_path, workspace_id, dataset_name):\n",
        "        \"\"\"\n",
        "        Deploy a Power BI report to the service\n",
        "        \"\"\"\n",
        "        if not self.access_token:\n",
        "            print(\"Not authenticated. Please authenticate first.\")\n",
        "            return False\n",
        "\n",
        "        headers = {\n",
        "            'Authorization': f'Bearer {self.access_token}',\n",
        "            'Content-Type': 'application/json'\n",
        "        }\n",
        "\n",
        "        # Import the PBIX file\n",
        "        import_url = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/imports\"\n",
        "\n",
        "        with open(file_path, 'rb') as f:\n",
        "            files = {\n",
        "                'file': (os.path.basename(file_path), f)\n",
        "            }\n",
        "            data = {\n",
        "                'datasetDisplayName': dataset_name,\n",
        "                'nameConflict': 'CreateOrOverwrite'\n",
        "            }\n",
        "\n",
        "            response = requests.post(import_url, headers=headers, files=files, data=data)\n",
        "\n",
        "            if response.status_code == 202:\n",
        "                print(\"Report deployed successfully!\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"Deployment failed: {response.text}\")\n",
        "                return False\n",
        "\n",
        "def main():\n",
        "    # Configuration - replace with your actual values\n",
        "    config = {\n",
        "        'client_id': 'your_client_id',\n",
        "        'client_secret': 'your_client_secret',\n",
        "        'tenant_id': 'your_tenant_id',\n",
        "        'workspace_id': 'your_workspace_id',\n",
        "        'dataset_name': 'Vaccination Analysis',\n",
        "        'pbix_file': 'vaccination_analysis.pbix'\n",
        "    }\n",
        "\n",
        "    # Initialize deployer\n",
        "    deployer = PowerBIDeployer(\n",
        "        config['client_id'],\n",
        "        config['client_secret'],\n",
        "        config['tenant_id']\n",
        "    )\n",
        "\n",
        "    # Authenticate\n",
        "    if deployer.authenticate():\n",
        "        # Deploy report\n",
        "        deployer.deploy_report(\n",
        "            config['pbix_file'],\n",
        "            config['workspace_id'],\n",
        "            config['dataset_name']\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaELeaZx3LuU",
        "outputId": "d28c6db0-650f-4f95-91bb-55171ff8c530"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication failed: {\"error\":\"invalid_request\",\"error_description\":\"AADSTS900023: Specified tenant identifier 'your_tenant_id' is neither a valid DNS name, nor a valid external domain. Trace ID: 1626a551-5872-4c62-8d5a-f5c3b9623501 Correlation ID: 81bb26ab-6cdb-458a-b4d0-929e48a450c4 Timestamp: 2025-09-07 06:28:46Z\",\"error_codes\":[900023],\"timestamp\":\"2025-09-07 06:28:46Z\",\"trace_id\":\"1626a551-5872-4c62-8d5a-f5c3b9623501\",\"correlation_id\":\"81bb26ab-6cdb-458a-b4d0-929e48a450c4\",\"error_uri\":\"https://login.microsoftonline.com/error?code=900023\"}\n"
          ]
        }
      ]
    }
  ]
}